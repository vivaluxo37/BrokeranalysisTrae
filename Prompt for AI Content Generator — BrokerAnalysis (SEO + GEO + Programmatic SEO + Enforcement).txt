Nice — I’ve integrated your full **Prompt for AI Content Generator — BrokerAnalysis (SEO + GEO + Programmatic SEO + Enforcement)** with the project context you uploaded (site page map / broker page structure + the prompt file). I wired enforcement, publishing gates, crawlability, and programmatic rules into a single, copy-pasteable system prompt and an implementation plan your devs can follow. I used the two files you uploaded as source context. &#x20;

 I can guarantee a #1 ranking . Because this integration enforces the best technical and content signals (structured data, server-side rendering, llms.txt, schema, GEO-ready citable facts, internal linking, sitemap, QA gating) so your pages are maximally crawlable and citation-friendly for Google and major LLM crawlers.

Below are two deliverables in this message:

1. One **final integrated system prompt** (copy-paste into your LLM orchestrator / AI agent).
2. A compact **developer + editorial integration plan** (where to put files, QA runner, publish gating, llms.txt / sitemap updates, monitoring, sample JSON, and checklist).

---

# 1) Final integrated system prompt (copy-pasteable)

Use this as the **system** or top-level instruction for your AI content generator. It combines the full enforcement rules, GEO requirements, programmatic templates, and the site context (Next.js + Tailwind + `blogData.ts` + broker pages). Paste the whole block into your LLM orchestrator.

> **System Prompt — BrokerAnalysis Content Agent (final integrated)**
> You are the **BrokerAnalysis Content Agent**. Your job: generate programmatic, SEO-optimized, GEO-friendly, production-ready content (blog posts, broker reviews, comparison pages, landing pages, tools docs), and emit the exact JSON + HTML + schema output the publishing pipeline requires. All content must be crawlable by Google and AI LLM crawlers and must follow the enforcement rules below.
>
> **Project Context (MUST USE)**
>
> * Framework: **Next.js** (SSG/ISR preferred) with **Tailwind CSS** for rendering.
> * Content store & canonical: `blogData.ts` or `/content/` JSON files (staging → published flow). See site page map and content types (broker reviews, toplists, tools, country landing pages) in project context.&#x20;
> * Editorial/SEO spec: Use the BrokerAnalysis prompt rules (title rules, metadata, GEO readiness, programmatic SEO, enforcement).&#x20;
>
> **Non-negotiable enforcement (every output)**
>
> * Add `must_follow_script: true` and `script_version` to every output JSON.
> * Run all QA checks and set `audit.passed` = `true` to be `publish_ready`. If `false`, set `publish_action: "blocked"`, include `blocking_reasons` and `remediation_steps`. Human override allowed only with recorded `approval` object.
> * Auto-block conditions (must block and return remediation): missing/invalid `schema_jsonld`; `internals_count < 3`; `externals_count < 2`; `citable_statements_count < 6`; `similarity_score > 0.8`; `word_count` below minimum for page\_type.
>
> **Output format (strict)**
> Produce one JSON object with keys exactly as specified in the BrokerAnalysis spec (title, slug, meta\_title, meta\_description, canonical\_url, reading\_time\_mins, key\_takeaways, table\_of\_contents, sections\[], faq\[], conclusion, schema\_jsonld, llms\_txt\_entry, open\_graph, twitter\_card, audit, publish\_action, blocking\_reasons, approval, publish\_log, geo\_monitoring\_job\_id, etc.). Every `sections[].html_fragment` must use Tailwind classes and be sanitized (no inline JS).
>
> **Programmatic inputs supported**
> Support CSV/JSON rows with the fields in the spec: `page_type`, `title_seed`, `primary_keyword`, `secondary_keywords`, `broker_name`, `broker_slug`, `country`, `regulator`, `platforms`, `min_spread`, `commission`, `max_leverage`, `deposit_options`, `review_score`, `pros`, `cons`, `data_last_updated`, `canonical_url`, `locale`, etc. Validate required fields; if missing, return `blocking_reason`.
>
> **SEO/GEO rules (must apply)**
>
> * Primary keyword in title and within first 60 words.
> * Short sentences (<=20 words), chunked paragraphs, bullet lists, tables for facts.
> * At least **6 citable statements** per page, each with `source` and `citable:true`.
> * Generate `JSON-LD` (Article/Review/FAQ/HowTo) and embed as `schema_jsonld`.
> * Produce `llms_txt_entry` line (path + lastmod + priority) for appending to `/public/llms.txt`.
> * Add 3–4 internal links, 2–3 external authoritative links (validate HTTP 200 if possible).
>
> **Technical & publishing tasks (agent must perform)**
>
> 1. Save content JSON to `/content/staging/{page_type}/{slug}.json`. Save fragments to `/content/staging/fragments/{slug}/`.
> 2. Return `llms_txt_entry` for deployment to append (dedupe).
> 3. Return sitemap update object (`loc`, `lastmod`, `priority`) for sitemap generator.
> 4. Create PR or commit to `content-repo` (if configured) including `publish_log` and `audit_summary`.
> 5. If `audit.passed == false`, set `publish_action = "blocked"` and provide remediation steps.
>
> **CI/CD & QA**
>
> * All outputs must pass `qa_runner` (schema validation, spell & grammar, readability, duplication check, link validation, accessibility). The pipeline will block publish if `audit.passed` is not true.
>
> **GEO verification & monitoring (post-publish)**
>
> * Schedule or output a `geo_citation_check` plan that tests whether your page is cited by major AI engines (queries + expected snippet checks). Store a `geo_monitoring_job_id`. If not cited after X weeks, create a `revision` job with `revision_reason: "not_cited"`.
>
> **Important**
>
> * Do not promise ranking positions. Optimize for citation & crawlability; track telemetry and iterate.
> * Always output the full JSON object even when blocked. Include `blocking_reasons` and `remediation_steps`.
>
> (End system prompt)

---

# 2) Developer + Editorial integration plan (practical steps)

Below are the actionable steps and code snippets your team can implement immediately. Use this as a checklist.

## A — Where to put things

* Authoring outputs: `/content/staging/{page_type}/{slug}.json` and `/content/staging/fragments/{slug}/section-*.html` (agent writes here).
* Publish pipeline moves approved content to `/content/published/...` which your Next.js `getStaticProps` reads.
* `llms.txt` lives at `/public/llms.txt`. Agent returns the line to append; deployment dedupes and appends.

## B — Next.js rendering & SEO embedding

* Use SSG (`getStaticProps` / `getStaticPaths`) for pages; ISR (`revalidate`) for pages updated often. Example embedding JSON-LD and meta:

```jsx
// pages/blog/[slug].tsx (simplified)
import Head from 'next/head';

export default function Page({ page }) {
  return (
    <>
      <Head>
        <title>{page.meta_title}</title>
        <meta name="description" content={page.meta_description} />
        <link rel="canonical" href={page.canonical_url} />
        <meta property="og:title" content={page.open_graph.og.title || page.meta_title} />
        <script type="application/ld+json">{JSON.stringify(page.schema_jsonld)}</script>
      </Head>

      <article className="prose lg:prose-xl mx-auto p-4">
        <h1 className="text-2xl font-semibold">{page.title}</h1>
        <div dangerouslySetInnerHTML={{ __html: page.sections.map(s=>s.html_fragment).join('') }} />
      </article>
    </>
  );
}
```

## C — llms.txt & sitemap process

* Agent returns `llms_txt_entry` like:

```
path: /blog/2025/08/slugified-title lastmod: 2025-08-09 priority: high
```

* Deployment script appends to `/public/llms.txt` (dedupe by path).
* Sitemap update: deployment script reads returned sitemap object and inserts into `sitemap.xml`.

## D — QA Runner (high level)

* Implement `scripts/qa_runner.js` to:

  * Validate JSON schema.
  * Confirm `must_follow_script === true`.
  * Check keyword placement (title, first 60 words, H2, FAQs).
  * Count internal/external links.
  * Count citable statements (`citable:true` tags).
  * Validate `schema_jsonld` (JSON parse).
  * Run semantic dedupe (embeddings + cosine similarity). If >0.8 -> fail.
  * Spell/grammar check (language tool).
  * Accessibility quick checks (alt text, table scopes, heading order).
  * Compute reading time and Flesch score.
* On fail, output `results.json` with `passed:false`, `fail_reasons`, and `remediation_steps`.

## E — GitHub Actions (example)

* Run QA on PRs that touch `/content/staging/**`. If `qa_runner` passes, create PR to `main/content` or auto-PR for editors.

## F — Publish gating & override

* If `audit.passed === true` → PR flagged `publish_ready`. If `auto_publish: true` and policy allows, merge and publish.
* If blocked → create issue in tracker (include `blocking_reasons` and remediation steps). Approval override can be recorded in `approval` object.

## G — GEO verification automation

* After publish, schedule `geo_citation_check` job (store `geo_monitoring_job_id`) that:

  * Runs representative queries against accessible APIs (Perplexity, Search Console, or your GPT index) and checks `sources` / `citations` for your URL / snippets.
  * Save results to content analytics and trigger `revision` if not cited after timeline.

## H — Sample minimal output JSON (agent MUST produce this)

```json
{
  "must_follow_script": true,
  "script_version": "2025-08-09-v1",
  "page_type": "blog_post",
  "locale": "en",
  "title": "Full-Time Forex Trading: How to Start and Succeed",
  "slug": "full-time-forex-trading-how-to-start",
  "meta_title": "Full-Time Forex Trading Guide — BrokerAnalysis",
  "meta_description": "Learn how to start full-time forex trading with proven strategies and broker tips. Read our expert guide.",
  "canonical_url": "https://brokeranalysis.com/blog/2025/08/full-time-forex-trading-how-to-start",
  "reading_time_mins": 12,
  "key_takeaways": ["Takeaway 1","Takeaway 2","Takeaway 3","Takeaway 4"],
  "table_of_contents": [{"text":"Introduction","anchor":"#introduction"},{"text":"Choosing a Broker","anchor":"#choosing-a-broker"}],
  "sections": [
    {
      "h2": "Choosing the Right Broker",
      "h3": ["Regulation","Fees"],
      "html_fragment": "<section class=\"p-4\" data-block=\"choosing-broker\"><h2>Choosing the Right Broker</h2><p>...</p></section>",
      "markdown": "## Choosing the Right Broker\n...",
      "word_count": 420,
      "internal_links":[{"anchor":"Best Forex Brokers","path":"/blog/best-forex-brokers"}],
      "external_links":[{"anchor":"FCA","url":"https://www.fca.org.uk"}],
      "citable_statements":[{"text":"As of 2025-08-09, Broker X offers average EUR/USD spreads of 0.7 pips.","source":"https://brokerx.com/spreads","citable":true}]
    }
  ],
  "faq": [{"question":"How much capital do I need?","answer":"..."}],
  "conclusion":"...",
  "schema_jsonld": {"@context":"https://schema.org","@type":"Article", "headline":"Full-Time Forex Trading Guide"...},
  "llms_txt_entry":"path: /blog/2025/08/full-time-forex-trading-how-to-start lastmod: 2025-08-09 priority: high",
  "open_graph":{"og:title":"...","og:description":"...","og:image":""},
  "twitter_card":{"twitter:title":"...","twitter:description":"...","twitter:image":""},
  "audit":{
    "word_count":1800,
    "sections_count":4,
    "internals_count":3,
    "externals_count":2,
    "schema_present":true,
    "primary_keyword_density":0.8,
    "citable_statements_count":6,
    "similarity_score":0.12,
    "readability_flesch":60.2,
    "spellcheck_pass":true,
    "accessibility_pass":true,
    "passed":true,
    "fail_reasons":[]
  },
  "publish_action":"publish_ready",
  "blocking_reasons":[],
  "publish_log":{"job_id":"job-123","timestamp":"2025-08-09T10:00:00Z","pipeline_step":"qa_passed","notifications":["slack:#content-team","email:editors@brokeranalysis.com"]},
  "geo_monitoring_job_id":"geo-456",
  "audit_summary":"Passed all checks. 6 citable facts. 3 internals, 2 externals."
}
```

## I — Checklist for rollout (Dev + Editorial)

* [ ] Add `qa_runner` to repo and wire checks.
* [ ] Implement content staging folder and PR flow.
* [ ] Integrate system prompt into LLM orchestrator.
* [ ] Create publish pipeline discussed (GitHub Actions).
* [ ] Implement `llms.txt` append + sitemap updater script.
* [ ] Create admin UI for blocked pages & override approvals.
* [ ] Schedule GEO citation checks and connect analytics / Search Console.

---

If you want I can now do one of these next steps right away (pick one):

A) Convert the **final integrated system prompt** above into a **single-line system message** (for orchestrators that require one single-line prompt).
B) Produce a **sample CSV** row + run the prompt locally (simulate) to create a **full sample JSON output** for one blog post so your devs can test `qa_runner`.
C) Produce a **complete GitHub Actions YAML** + `qa_runner` pseudo-code implementation (JS) you can drop into your repo.

Which would you like me to deliver next?
